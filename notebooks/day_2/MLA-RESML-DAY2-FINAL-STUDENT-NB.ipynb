{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLU Logo](../../data/MLU_Logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"0\">Responsible ML - Final Project</a>\n",
    "\n",
    "Build a fair [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) that predicts the __credit_risk__ field (whether loan is repaid or not) of the [German Credit Dataset](https://archive.ics.uci.edu/ml/datasets/South+German+Credit+%28UPDATE%29).\n",
    "\n",
    "### Final Project Problem: Loan Approval\n",
    "\n",
    "__Problem Definition__:\n",
    "Given a set of features about an individual (e.g. age, past credit history, immigration status, ...) predict whether a loan is repaid or not (is customer a credit risk). We impose the additional constraint that the model should be fair with respect to different age groups ($\\geq$ 25y and $<$ 25y).\n",
    ", in the banking industry, there are certain patterns that could be illegal. One of illegal patterns would be age playing a significant role (loans should be approved/denied regardless of an individuals age).\n",
    "\n",
    "For example, certain laws declare it unlawful for creditors to discriminate against any applicant on the basis of age (or other sensitive attributes). For more details, have a look at this paper:\n",
    "\n",
    "``` \n",
    "F. Kamiran and T. Calders, \"Data Preprocessing Techniques for Classification without Discrimination,\" Knowledge and Information Systems, 2012\n",
    "```\n",
    "\n",
    "1. <a href=\"#1\">Read the datasets</a> (Given) \n",
    "2. <a href=\"#2\">Data Processing</a> (Implement)\n",
    "    * <a href=\"#21\">Exploratory Data Analysis</a>\n",
    "    * <a href=\"#22\">Select features to build the model</a> (Suggested)\n",
    "    * <a href=\"#23\">Train - Validation - Test Datasets</a>\n",
    "    * <a href=\"#24\">Data Processing with Pipeline</a>\n",
    "3. <a href=\"#3\">Train (and Tune) a Classifier on the Training Dataset</a> (Implement)\n",
    "4. <a href=\"#4\">Make Predictions on the Test Dataset</a> (Implement)\n",
    "5. <a href=\"#5\">Evaluate Results</a> (Given)\n",
    "\n",
    "\n",
    "__Datasets and Files:__\n",
    "\n",
    "\n",
    "- ```german_credit_training.csv```: Training data with loan applicants features, credit history, dependents, savings, account status, age group (and more). The label is __credit_risk__.\n",
    "\n",
    "- ```german_credit_test.csv```: Test data with same features as above apart from label. This will be the data to make predictions for to emulate a production environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping/basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from aif360.datasets import BinaryLabelDataset, Dataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.algorithms.preprocessing import DisparateImpactRemover\n",
    "\n",
    "# Operational libraries\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Jupyter(lab) libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the datasets</a> (Given)\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we read the __training__ and __test__ datasets into dataframes, using [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html). This library allows us to read and manipulate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../../data/final_project/german_credit_training.csv')\n",
    "test_data = pd.read_csv('../../data/final_project/german_credit_test.csv')\n",
    "\n",
    "print('The shape of the training dataset is:', training_data.shape)\n",
    "print('The shape of the test dataset is:', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Data Processing</a> (Implement)\n",
    "(<a href=\"#0\">Go to top</a>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 <a name=\"21\">Exploratory Data Analysis</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We look at number of rows, columns, and some simple statistics of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement more EDA here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 <a name=\"22\">Select features to build the model</a> \n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Let's use all the features today. Below you see a snippet of code that separates categorical and numerical columns based on their data type. This should only be used if we are sure that the data types are correctly assigned (check during EDA). Mindful with some of the feature names - they suggest numerical values but upon inspection it should become clear that they are actually categoricals (e.g. `employed_since_years` has been binned into groups).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab model features/inputs and target/output\n",
    "categorical_features = training_data.drop('credit_risk',axis = 1).select_dtypes(include='object').columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_features)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "numerical_features = training_data.drop('credit_risk',axis = 1).select_dtypes(include=np.number).columns.tolist()\n",
    "print(\"Numerical columns:\", numerical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that `ID` is identified as numerical column. ID's should never be used as features for training as they are unique by row. Let's drop the ID from the model features after we have separated target and features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_target = \"credit_risk\"\n",
    "model_features = categorical_features + numerical_features\n",
    "\n",
    "print(\"Model features: \", model_features)\n",
    "print(\"\\n\")\n",
    "print(\"Model target: \", model_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = \"ID\"\n",
    "\n",
    "# Drop 'ID' feature from the respective list(s)\n",
    "if to_remove in model_features:\n",
    "    model_features.remove(to_remove)\n",
    "if to_remove in categorical_features:\n",
    "    categorical_features.remove(to_remove)\n",
    "if to_remove in numerical_features:\n",
    "    numerical_features.remove(to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 <a name=\"23\">Feature transformation</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Here, you have different options. You can use Reweighing, Disparate Impact Remover or Suppression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 <a name=\"23\">Train - Validation Datasets</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "We already have training and test datasets, however the test dataset is missing the labels - the goal of the project is to predict these labels. \n",
    "\n",
    "To produce a validation set to evaluate model performance, split the training dataset into train and validation subsets using sklearn's [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function. Validation data you get here will be used later in section 3 to tune your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 <a name=\"25\">Data processing with Pipeline</a>\n",
    "(<a href=\"#2\">Go to Data Processing</a>)\n",
    "\n",
    "Build a [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)  to impute the missing values and scale the numerical features, and finally train a [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)  on the imputed and scaled dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Train (and Tune) a Classifier</a> (Implement)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Train (and tune) the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) pipeline. For tuning, you can try different imputation strategoes, different scaling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Make Predictions on the Test Dataset</a> (Implement)\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Use the trained classifier to predict the labels on the test set. Below you will find a code snippet that evaluates for DI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "\n",
    "# Get test data to test the classifier\n",
    "# ! test data should come from german_credit_test.csv !\n",
    "# ...\n",
    "\n",
    "# Use the trained model to make predictions on the test dataset\n",
    "# test_predictions = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Evaluate Results</a> (Given)\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame(columns=[\"ID\", \"credit_risk\"])\n",
    "result_df[\"ID\"] = test_data[\"ID\"].tolist()\n",
    "result_df[\"credit_risk\"] = test_predictions\n",
    "\n",
    "result_df.to_csv(\"../../data/final_project/project_day2_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation on Test Data - Disparate Impact\n",
    "To evaluate the fairness of the model predictions, we will calculate the disparate impact (DI) metric. For more details about DI you can have a look [here](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-post-training-bias-metric-di.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_di(test_data, pred_df):\n",
    "    \"\"\"\n",
    "    Function to calculate Disparate Impact metric using the results from this notebook.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Merge predictions with original test data to model per group\n",
    "        di_df = pred_df.merge(test_data, on='ID')\n",
    "        # Count for group with members less than 25y old \n",
    "        pos_outcomes_less25 = di_df[di_df['age_groups']==0]['credit_risk_pred'].value_counts()[0] # value_counts()[0] takes the count of the '0 credit risk' == 'not credit risk'\n",
    "        total_less25 = len(di_df[di_df['age_groups']==0])\n",
    "        # Count for group with members greater equal 25y old\n",
    "        pos_outcomes_geq25 = di_df[di_df['age_groups']==1]['credit_risk_pred'].value_counts()[0] # value_counts()[0] takes the count of the '0 credit risk' == 'not credit risk'\n",
    "        total_geq25 = len(di_df[di_df['age_groups']==1])\n",
    "        # Check if correct number of gorups\n",
    "        if total_geq25 == 0:\n",
    "            print('There is only one group present in the data.')\n",
    "        elif total_less25 == 0:\n",
    "            print('There is only one group present in the data.')\n",
    "        else:\n",
    "            disparate_impact = (pos_outcomes_less25/total_less25)/(pos_outcomes_geq25/total_geq25)\n",
    "            return disparate_impact\n",
    "    except:\n",
    "        print(\"Wrong inputs provided.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_di(test_data, result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Evaluation on Test Data - Accuracy & F1 Score\n",
    "In addition to fairness evaluation, we also need to check the general model performance. During the EDA stage we learnt that the target distribution is skewed so we will use F1 score in addition to accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pd.read_csv('../../data/final_project/german_credit_test_labels.csv')['credit_risk'], result_df['credit_risk_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(pd.read_csv('../../data/final_project/german_credit_test_labels.csv')['credit_risk'], result_df['credit_risk_pred'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful if you plan to use AIF360 in the `Feature Transformation` section: You will have to transform the columns back to their original data types before passing them into the Sklearn pipeline. Also, you will have to apply the transformation to the test dataset seperatly as you are working with data that has already been split. Any transformation we apply (such as DI removal) needs to be added to all data set splits. Also, AIF360 expects to receive numerical columns only, so you will need to apply the data processor to convert your dataframe. In summary (if you plan to use AIF360):\n",
    "1. Convert your data to numerical values only\n",
    "2. Create BinaryLabelDataset\n",
    "3. Apply transformation to all splits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mlu_kernel",
   "language": "python",
   "name": "conda_mlu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
